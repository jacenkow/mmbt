model_config:
  unimodal_bert:
    bert_model_name: bert-base-uncased
    finetune_lr_multiplier: 1
    freeze_complete_base: false
    freeze_text: false
    hidden_dropout_prob: 0.1
    losses:
      - type: weighted_logit_bce
    num_labels: 14
    text_encoder:
      type: transformer
      params:
        bert_model_name: ${model_config.unimodal_bert.bert_model_name}
        hidden_act: gelu
        hidden_size: 768
        layer_norm_eps: 1e-12
        num_hidden_layers: 12
        num_attention_heads: 12
        output_attentions: false
        output_hidden_states: false
    text_hidden_size: 768
    training_head_type: classification
