{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation - Class Statistics\n",
    "\n",
    "Some helper methods to visualise the predictions and calculate per-class\n",
    "statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    multilabel_confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    0: \"Atelectasis\",\n",
    "    1: \"Cardiomegaly\",\n",
    "    2: \"Consolidation\",\n",
    "    3: \"Edema\",\n",
    "    4: \"Enlarged Cardiomediastinum\",\n",
    "    5: \"Fracture\",\n",
    "    6: \"Lung Lesion\",\n",
    "    7: \"Lung Opacity\",\n",
    "    8: \"No Finding\",\n",
    "    9: \"Pleural Effusion\",\n",
    "    10: \"Pleural Other\",\n",
    "    11: \"Pneumonia\",\n",
    "    12: \"Pneumothorax\",\n",
    "    13: \"Support Devices\",\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, axes, class_label,\n",
    "                           class_names, fontsize=14):\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0,\n",
    "                                 ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45,\n",
    "                                 ha='right', fontsize=fontsize)\n",
    "\n",
    "    axes.set_xlabel(\"Prediction\")\n",
    "    axes.set_ylabel(\"Truth\")\n",
    "    axes.set_title(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_statistics(results):\n",
    "    predictions = [(\n",
    "        np.array(i['probabilities']) > THRESHOLD).astype(int) for i in results]\n",
    "    ground_truth = [i['ground_truth'] for i in results]\n",
    "    probabilities = [i['probabilities'] for i in results]\n",
    "    \n",
    "    # Confusion matrix.\n",
    "    cm_image = multilabel_confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(12, 7))\n",
    "\n",
    "    for axes, cfs_matrix, label in zip(ax.flatten(), cm_image, LABELS.values()):\n",
    "        print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report.\n",
    "    print(\"Classification Report\")\n",
    "    print(\"-\" * 80)\n",
    "    print(classification_report(ground_truth, predictions,\n",
    "                                target_names=LABELS.values()))\n",
    "\n",
    "    # AUROC.\n",
    "    print(\"Area Under an ROC Curve\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    roc = 0\n",
    "\n",
    "    for i, j in enumerate(zip(np.array(ground_truth).T,\n",
    "                              np.array(probabilities).T)):\n",
    "        _roc = roc_auc_score(j[0], j[1])\n",
    "        roc += _roc\n",
    "        print(LABELS[i], \"%.4f\" % _roc)\n",
    "\n",
    "    print(\"Average:\", \"%.4f\" % float(roc / 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PREFIX = \"../training\"\n",
    "\n",
    "for i in glob(os.path.join(PREFIX, \"*training*\",\n",
    "                           \"mimic*\", \"reports\", \"*json\")):\n",
    "    print(\"*\" * 80)\n",
    "    print(i.split(\"/\")[7])\n",
    "    print(\"*\" * 80)\n",
    "    \n",
    "    with open(i, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    return_statistics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}